{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEHALZuVI1dJ"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df= pd.read_csv('/content/urbansound8k/data.csv')\n",
        "df.head(5)\n",
        "\n",
        "import librosa\n",
        "audio_file_path='/content/urbansound8k/fold10/100648-1-0-0.wav'\n",
        "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)\n",
        "\n",
        "print(librosa_audio_data)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(librosa_audio_data)\n",
        "\n",
        "# @title Import Modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, librosa\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers, Sequential\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "mfccs = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
        "\n",
        "mfccs\n",
        "\n",
        "# @title DataPath\n",
        "audio_dataset_path = '/content/data'\n",
        "metadata =  pd.read_csv('/content/urbansound8k/data.csv')\n",
        "metadata.head()\n",
        "\n",
        "def mfccExtract(file):\n",
        "    waveform, sampleRate = librosa.load(file_name)\n",
        "    features = librosa.feature.mfcc(y = waveform, sr = sampleRate, n_mfcc = 50)\n",
        "    return np.mean(features, axis = 1)\n",
        "\n",
        "extractAll = []\n",
        "\n",
        "for index_num, row in tqdm(metadata.iterrows()):\n",
        "    # Constructing file path\n",
        "    file_name = os.path.join(audio_dataset_path, 'fold' + str(row['fold']), row['slice_file_name'])\n",
        "\n",
        "    # Extracting features and appending them\n",
        "    features = mfccExtract(file_name)\n",
        "    extractAll.append([features, row['class']])\n",
        "\n",
        "featuresDf = pd.DataFrame(extractAll, columns = ['Features', 'Class'])\n",
        "featuresDf.head()\n",
        "\n",
        "X=np.array(featuresDf['Features'].tolist())\n",
        "Y=np.array(featuresDf['Class'].tolist())\n",
        "\n",
        "labelencoder=LabelEncoder()\n",
        "Y=to_categorical(labelencoder.fit_transform(Y))\n",
        "\n",
        "Y\n",
        "\n",
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
        "num_labels=Y.shape[1]\n",
        "\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from keras.layers import *\n",
        "base_model = VGG19(weights='imagenet',\n",
        "                       include_top=False,\n",
        "                       input_shape=(32, 32, 3))\n",
        "\n",
        "from tensorflow.keras.models import  Model\n",
        "# Add classification layers on top of it\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu',input_shape = (50,))(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 10)\n",
        "\n",
        "test_accuracy=model.evaluate(X_test,Y_test,verbose=0)\n",
        "print(test_accuracy[1])\n",
        "\n",
        "historyDf = pd.DataFrame(history.history)\n",
        "\n",
        "historyDf.loc[:, ['loss', 'val_loss']].plot()\n",
        "\n",
        "historyDf.loc[:, ['accuracy', 'val_accuracy']].plot()\n",
        "\n",
        "# Evaluating model\n",
        "score = model.evaluate(X_test, Y_test)[1] * 100\n",
        "print(f'Validation accuracy of model : {score:.2f}%')"
      ]
    }
  ]
}